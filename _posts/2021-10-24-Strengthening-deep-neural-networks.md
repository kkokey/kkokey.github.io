---
title: '[도서 리뷰] Strengthening Deep Neural Networks'
date: 2021-10-24 15:35:00
categories: 도서리뷰
tags: 개발자 developer deep neural networks 한빛미디어 o'reilly
comments: true
---

<img src='https://firebasestorage.googleapis.com/v0/b/github-blog-39e5f.appspot.com/o/deep-neural-networks.JPG?alt=media&token=e53d77d8-378b-47d3-8667-aed4fe2fc5de' width='300px'/>

안녕하세요 괴짜 개발자 namedboy 입니다. 😎

심층 신경망 인공지능 하면 어떤 단어들이 떠오르시나요?
인공, 복잡한, 어려운, 복잡계, 컴퓨터 등등 여러 단어들이 연관되어 있죠.
AI 인공지능은 완벽하다고 생각하시나요?
이 주제에 대해서는 학계에서도 계속해서 논의가 되고 있지요.
이 책에서는 인공지능도 완벽하지 않다는 것을 보여주고 또 그것을 보완하기 위해 어떤 방법이 필요한지에 대해 얘기하고 있습니다.

책에서 예를 들어 설명한 것은 적대적 공격을 통해 AI의 이미지 인식을 방해하는 방법입니다.
사람이 보기에는 별로 문제가 될 것 없는 일종의 마크 같은 것들을 이미지에 심어서 AI에게 의도적으로 오류를 도출하게 만드는 것이지요.

[적대적 공격의 예](https://www.hani.co.kr/arti/science/future/898163.html)
링크에 나오는 내용은 STOP 표지만 이지만 특정 영역에 스티커를 붙여 AI가 STOP으로 인식하지 못하는 이미지 오류에 대해 설명하고 있습니다.
이런 이미지가 도로표지만에 실제 있다면 자동차에 탑재된 AI는 저걸 다르게 해석해서 멈추지 않고 직진을 하게 되겠죠.
그렇게 되면 인명사고까지도 만들어질 수 있는 위험한 상황이 벌어질 수 있게 됩니다.

AI가 점점 더 발전하고 많은 판단을 AI가 하게 되면서부터 이런 문제에 대해 대비해야 하는 상황이 만들어지고 있습니다.
이러한 문제를 해결하기 위해서는 여러 방향의 접근법을 통해 시도를 해야 하고 장기적으로는 모델의 개선을 통해 이러한 위협에 대해 대응하여 적대적 공격도 회피할 수 있는 AI가 구현되도록 노력해야 합니다.
명확하게 인지하고 제대로 처리할 수 있도록 돕는거죠.

결국 AI가 점점 더 발전하고 연구자들이 이런 적대적 공격에 대한 대응방법을 찾아내고 인간의 뇌와 더 비슷하게 논리를 만들어낼 수 있도록 모델을 개선하는 노력을 한다면 이런 공격을 할 수 없는 날이 도래하겠지요.

저는 단순한 사례와 방어법의 개략적인 내용을 설명했지만, 책에는 기술적으로 막아낼 수 있도록 어떻게 구현하는지에 대한 내용이 담겨있습니다.
AI 모델을 개발하시는 분이나 해당 모델을 가지고 시스템에 반영하시는 분들에게는 도움이 될 수 있겠네요.

책은 [링크](https://www.hanbit.co.kr/store/books/look.php?p_code=B2392091284)에서 구매하실 수 있습니다.
이 리뷰는 한빛미디어 &lt;나는 리뷰어다&gt; 활동을 위해서 책을 제공받아 작성된 서평입니다.